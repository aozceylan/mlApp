import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import pickle
# Notwendige Imports fÃ¼r diesen Abschnitt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
        accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
        confusion_matrix, classification_report, roc_curve, auc, log_loss
    )
import matplotlib
matplotlib.use('Agg')  # Set backend before importing pyplot
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import plotly.express as px

import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
import os


st.set_page_config(page_title="ML Workflow", layout="wide")

# Ä°lk Ã¶nce is_home_page fonksiyonunu kullanmadan Ã¶nce active_components decd ÄŸiÅŸkeninin
# var olduÄŸundan emin olmak iÃ§in kontrol ekleyelim
if 'active_components' not in st.session_state:
    st.session_state.active_components = {
        "data_import": False,
        "data_visualization": False,
        "select_columns": False,
        "data_sampling": False,
        "modeling": False,
        "evaluation": False,
        "prediction": False 
    }

def is_home_page():
    # EÄŸer hiÃ§bir component aktif deÄŸilse veya sadece ana sayfa aktifse
    return not any(st.session_state.active_components.values()) or (
        st.session_state.active_components.get("data_import", False) == False and
        st.session_state.active_components.get("data_visualization", False) == False and
        st.session_state.active_components.get("select_columns", False) == False and
        st.session_state.active_components.get("data_sampling", False) == False and
        st.session_state.active_components.get("modeling", False) == False and
        st.session_state.active_components.get("evaluation", False) == False
    )
def apply_custom_styling():
    home_page = is_home_page()
    top_right_size = "200px" if home_page else "200px"
    top_right_left = "100px" if home_page else "100px"
    
    bottom_left_size = "700px" if home_page else "500px"
    bottom_left_right = "300px" if home_page else "300px"
    
    # f-string kullanarak dinamik deÄŸerleri CSS'e ekleyelim
    st.markdown(f"""
     <style>
        /* Daha spesifik CSS seÃ§icileri */
        div[data-testid="stHeader"] {{display: none;}}
        
        .stApp h1,
        .stApp .stMarkdown h1,
        .stApp header h1,
        section[data-testid="stSidebar"] + div h1,
        .main .block-container h1 {{
            color:#007E92 !important;
            text-align: center !important;
            font-size: 2.5rem !important;
            padding: 1rem 0 !important;
        }}
        
        /* Streamlit Ã¼st Ã§ubuÄŸunu gizlemek */
        header {{
            visibility: hidden;
        }} 

        /* Sayfa Ã¼st boÅŸluÄŸunu tamamen kaldÄ±r */
        .block-container {{
            padding-top: 0 !important;
            margin-top: 0 !important;
        }}

        /* Logo-Container ile logoyu yukarÄ± kaydÄ±rma */
        .logo-container {{
            position: absolute;
            top: -100px;  /* Logo'yu yukarÄ± kaydÄ±r */
            left: 0;
            padding: 5px;
            z-index: 1000;
        }}

        /* Global Styling */
        .stApp {{
            background-color: #ffffff; /* Beyaz arka plan */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }}

        /* Sidebar Styling */
        div[data-testid="stSidebar"] {{
            background-color: #ffffff !important;
            border-right: 2px solid #e0e0e0;
            box-shadow: 2px 0 5px rgba(0,0,0,0.0);
        }}

        .css-1aumxhk {{
            background-color: #ffffff;
        }}

        .stApp {{
            background-image: url("./images/logo2.png");
            background-size: cover;
        }}
        
        .stApp {{
            background-color: rgba(0, 0, 0, 0);  /* Arka planÄ± ÅŸeffaf yap */
        }}        

        /* Yatay Ã§izgi */
        .horizontal-line {{
            border-top: 1px solid #333;
            margin: 20px 0;
        }}

        /* Button Styling */
        .stButton>button {{
            background-color: #007E92; /* Buton rengi */
            color: white;
            border-radius: 8px;
            border: none;
            transition: all 0.3s ease;
        }}

        .stButton>button:hover {{
            background-color: #005f6b; /* Hover rengi */
            transform: scale(1.05);
        }}

        /* Header Styling */
        h1, h2, h3, h4, h5, h6 {{
            color: #2c3e50;
            font-weight: 600;
        }}

        /* Card-like containers */
        .stDataFrame, .stTable {{
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            padding: 10px;
            margin-bottom: 20px;
        }}

        /* Chart and Plot Styling */
        .stPlotlyChart {{
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            padding: 10px;
        }}

        /* Metric Styling */
        .stMetric {{
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            padding: 15px;
        }}

        /* Radio and Select Widgets */
        .stRadio, .stSelectbox {{
            background-color: white;
            border-radius: 8px;
            padding: 10px;
        }}

        /* Progress and Spinner */
        .stSpinner > div {{
            border-color: #007E92 transparent #007E92 transparent;
        }}

        /* Tabs Styling */
        .stTabs [data-baseweb="tab-list"] {{
            background-color: #f0f2f6;
            border-radius: 10px;
        }}

        .stTabs [data-baseweb="tab"] {{
            color: #2c3e50;
            background-color: transparent;
            transition: all 0.3s ease;
        }}

        .stTabs [data-baseweb="tab"]:hover {{
            color: #007E92; /* Hover rengi */
        }}

        .stTabs [data-baseweb="tab"][aria-selected="true"] {{
            background-color: #007E92; /* SeÃ§ili sekme rengi */
            color: white;
        }}
        
        /* Obere rechte Ecke Dreieck - angepasst nach Seitentyp */
        .top-right-triangle {{
            position: fixed;
            top: 0;
            right: 0;
            width: 0;
            height: 0;
            border-top: {top_right_size} solid #007E92;
            border-left: {top_right_left} solid transparent;
            z-index: 999;
        }}
           
          
        /* =============== GELÄ°ÅžMÄ°Åž CSS KODLARI =============== */
        
        /* Multiselect tag'leri iÃ§in renkleri Ã¶zelleÅŸtirme */
        span[data-baseweb="tag"] {{
            background-color: #007E92 !important;
            color: white !important;
            border-color: #007E92 !important;
        }}

        span[data-baseweb="tag"] span {{
            color: white !important;
        }}

        span[data-baseweb="tag"]:hover {{
            background-color: #005f6b !important;
        }}

        span[data-baseweb="tag"] button {{
            color: white !important;
        }}

        /* Streamlit default checkbox stilini deÄŸiÅŸtirme */
        [role="checkbox"][data-baseweb="checkbox"] {{
            background-color: #007E92 !important;
        }}
        .st-emotion-cache-1dj3ksd e8lt0n70,
        [role="slider"] {{
        background-color: #008E88 !important; /* Ä°stediÄŸiniz rengi buraya yazÄ±n */
        }}
        [data-baseweb="slider"] div[role="slider"] + div div {{
        background-color:#008E88 !important;
        }}
        
        /* Sadece dolgu kÄ±smÄ±nÄ± hedefle */
        [data-testid="stSlider"] [data-baseweb="slider"] div div div div {{
        background-color: #008E88 !important;
        }}
        /* Hareketli thumb noktasÄ±nÄ± hedefle */
        [data-testid="stSlider"] [role="slider"] {{
        background-color: #FF5733 !important;
        }}
                .st-emotion-cache-b92z60,
        [data-testid="stSliderThumbValue"] {{
        background-color: #008E88 !important; /* SayÄ± kutucuÄŸunun arkaplan rengi */
        color: white !important; /* SayÄ± rengi */
        }}
        /* Checkbox iÃ§in ek seÃ§iciler */
        [data-testid="stCheckbox"] > div[role="checkbox"] {{
            background-color: #007E92 !important;
            border-color: #007E92 !important;
        }}

        /* Checkbox iÅŸaretini beyaz yap */
        [data-testid="stCheckbox"] > div[role="checkbox"] > svg {{
            color: white !important;
        }}

        /* Radio button iÃ§in ek seÃ§iciler */
        [data-testid="stRadio"] label div[role="radio"][data-checked="true"] {{
            background-color: #007E92 !important;
            border-color: #007E92 !important;
        }}

        [data-testid="stRadio"] label div[role="radio"][data-checked="true"] div {{
            background-color: white !important;
        }}

        /* MultiSelect seÃ§ili etiketler iÃ§in stil */
        div[data-baseweb="select"] > div > div > div > div > div > div span[data-baseweb="tag"] {{
            background-color: #007E92 !important;
            color: white !important;
        }}

        /* MultiSelect etiketlerdeki Ã§arpÄ± iÅŸareti */
        div[data-baseweb="select"] > div > div > div > div > div > div span[data-baseweb="tag"] svg {{
            color: white !important;
        }}

        /* MultiSelect etiketleri kenar renkleri */
        div[data-baseweb="select"] > div > div > div > div > div > div span[data-baseweb="tag"] div {{
            border-color: #007E92 !important;
        }}

        /* AÃ§Ä±lÄ±r oku deÄŸiÅŸtir */
        div[data-baseweb="select"] > div > div > div:last-child > svg {{
            color: #007E92 !important;
        }}
        
        /* Dropdown ve selectbox stillerini deÄŸiÅŸtir */
        div[data-baseweb="select"] {{
            font-weight: 400;
        }}

        div[data-baseweb="select"] > div {{
            background-color: white;
            border-color: #007E92;
        }}

        div[data-baseweb="select"]:hover > div {{
            border-color: #005f6b;
        }}

        div[data-baseweb="base-input"] > div {{
            background-color: white;
            border-color: #007E92;
        }}

        div[data-baseweb="base-input"]:hover > div {{
            border-color: #005f6b;
        }}
        .stRadio label div[role="radio"] {{
           border-color: #007E92 !important;
        }}

        .stRadio label div[role="radio"][data-checked="true"] div {{
            background-color: #007E92 !important;
        }}


        /* Checkbox stilini deÄŸiÅŸtir */
        .stCheckbox > div > div > label > div[role="checkbox"] {{
            border-color: #007E92;
        }}

        .stCheckbox > div > div > label > div[data-checked="true"] {{
            background-color: #007E92;
            border-color: #007E92;
        }}
        
            
        
     </style>
     <div class="top-left-triangle"></div>
     <div class="top-right-triangle"></div>
     <div class="bottom-left-triangle"></div>
     <div class="bottom-right-triangle"></div>
    """, unsafe_allow_html=True)
# Logo kÄ±smÄ±nÄ± apply_custom_styling fonksiyonundan sonra Ã§aÄŸÄ±rmalÄ±yÄ±z
# BÃ¶ylece CSS stillemesi doÄŸru ÅŸekilde uygulanacaktÄ±r
apply_custom_styling()

# Åžimdi logoyu ekleyelim
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    image_path = os.path.join(os.path.dirname(__file__), "images", "logo1.png")
    st.image(image_path)
st.title("ML Workflow")
# Seitenkonfiguration
#st.set_page_config(page_title="ML Workflow ", layout="wide")

# Initialisierung von session_state Variablen, falls sie noch nicht existieren
if 'data' not in st.session_state:
    st.session_state.data = None
if "serialized_model" not in st.session_state:
    st.session_state.serialized_model = None
if "model_to_save" not in st.session_state:
    st.session_state.model_to_save = None    
if 'selected_columns' not in st.session_state:
    st.session_state.selected_columns = None
if 'sampled_data' not in st.session_state:
    st.session_state.sampled_data = None
if 'X_train' not in st.session_state:
    st.session_state.X_train = None
if 'X_test' not in st.session_state:
    st.session_state.X_test = None
if 'y_train' not in st.session_state:
    st.session_state.y_train = None
if 'y_test' not in st.session_state:
    st.session_state.y_test = None
if 'model' not in st.session_state:
    st.session_state.model = None
if 'predictions' not in st.session_state:
    st.session_state.predictions = None
if 'active_components' not in st.session_state:
    st.session_state.active_components = {
        "data_import": False,
        "data_visualization": False,
        "select_columns": False,
        "data_sampling": False,
        "modeling": False,
        "evaluation": False,
        "prediction": False 
    }

# Funktion zum Aktivieren eines bestimmten Workflow-Schritts
def activate_component(component_name):
    st.session_state.active_components = {k: False for k in st.session_state.active_components}
    st.session_state.active_components[component_name] = True
    st.rerun()
# Seitenleiste mit Workflow-Komponenten
st.sidebar.title("ML Workflow")
st.sidebar.write("WÃ¤hlen Sie die Schritte fÃ¼r Ihren ML-Workflow aus")

# Komponenten in der Seitenleiste
components = {
    "data_import": "1. Daten importieren",
    "data_visualization": "2. Daten visualisieren",
    "select_columns": "3. Datenbereinigung",
    "data_sampling": "4. Daten-Sampling",
    "modeling": "5. Modellierung",
    "evaluation": "6. Modell-Evaluation",
    "vorhersage":"7. Vorhersage"
}

# Buttons fÃ¼r jeden Workflow-Schritt
for key, label in components.items():
    # Buttons nur aktivieren, wenn Voraussetzungen erfÃ¼llt sind
    disabled = False
    
    if key == "data_visualization" and st.session_state.data is None:
        disabled = True
    elif key == "select_columns" and st.session_state.data is None:
        disabled = True
    elif key == "data_sampling" and st.session_state.selected_columns is None:
        disabled = True
    elif key == "modeling" and st.session_state.sampled_data is None:
        disabled = True
    elif key == "evaluation" and (not 'models' in st.session_state or len(st.session_state.models) == 0):
        disabled = True
    elif key == "vorhersage" and (not 'models' in st.session_state or len(st.session_state.models) == 0):
        disabled = True    
    if st.sidebar.button(label, disabled=disabled, key=f"btn_{key}"):
        activate_component(key)

# Hauptbereich
# 1. Daten importieren
if st.session_state.active_components["data_import"]:
    st.header("1. Daten importieren")
    st.markdown("""
    ### Datensatz-Beschreibung
    
    * **Atmo (low, medium, high)** - mit UmgebungsgerÃ¤uschen
    * **Whitenoise** - mit weiÃŸem Rauschen Ã¼berlagert
    * **Talking** - Menschen reden in der NÃ¤he
    * **Stress** - hohe Belastung und LautstÃ¤rke
    * **Combined** - alles zusammen
    * **Pure** - nur die MotorgerÃ¤usche ohne StÃ¶rungen
    """)
if st.session_state.active_components["data_import"]:
    st.header("1. Daten importieren")
    
    # Option zum Hochladen einer CSV-Datei oder Verwendung von Beispieldaten
    data_option = st.radio(
        "Datenquelle auswÃ¤hlen",
        ["CSV-Datei hochladen"]
    )
    
    if data_option == "CSV-Datei hochladen":
        uploaded_file = st.file_uploader("WÃ¤hlen Sie eine CSV-Datei", type="csv")
        if uploaded_file is not None:
            st.session_state.data = pd.read_csv(uploaded_file)
            st.success("Daten erfolgreich geladen!")
            # Nach erfolgreicher Datenladung automatisch zum nÃ¤chsten Schritt
            st.rerun()
        
    # Zeige die Daten an, wenn sie geladen sind
    if st.session_state.data is not None:
        st.write("Vorschau der Daten:")
        st.dataframe(st.session_state.data.head(10))
        st.write(f"Form: {st.session_state.data.shape[0]} Zeilen, {st.session_state.data.shape[1]} Spalten")
        
        # Button zum Fortfahren
        if st.button("Weiter zur Datenvisualisierung"):
            activate_component("data_visualization")
            st.experimental_rerun()

# 2. Daten visualisieren
elif st.session_state.active_components["data_visualization"]:
    st.header("2. Daten visualisieren")
    
    if st.session_state.data is not None:
        # Zwei Tabs fÃ¼r verschiedene Visualisierungsarten
        viz_tab1, viz_tab2 = st.tabs(["Scatter Plot", "Feature-Statistiken"])
        
        with viz_tab1:
            st.subheader("Scatter Plot")
            
            # Auswahl der Spalten fÃ¼r x und y
            numeric_columns = st.session_state.data.select_dtypes(include=['float64', 'int64']).columns.tolist()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                x_col = st.selectbox("X-Achse", options=numeric_columns, index=0)
            with col2:
                y_col = st.selectbox("Y-Achse", options=numeric_columns, index=1 if len(numeric_columns) > 1 else 0)
            with col3:
                color_col = st.selectbox("FÃ¤rben nach", options=st.session_state.data.columns)
            
            # Scatter Plot mit Plotly
            fig = px.scatter(
                st.session_state.data, 
                x=x_col, 
                y=y_col, 
                color=color_col,
                title=f"Scatter Plot: {x_col} vs {y_col}",
                labels={x_col: x_col, y_col: y_col},
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)
            
        with viz_tab2:
            st.subheader("Feature-Statistiken")
            
            # Deskriptive Statistiken
            st.write("Deskriptive Statistiken")
            
            # Describe ile istatistikleri al ve virgÃ¼lden sonra 2 rakam gÃ¶sterecek ÅŸekilde biÃ§imlendir
            desc_df = st.session_state.data.describe()
            
            # TÃ¼m sayÄ±sal deÄŸerleri virgÃ¼lden sonra 2 rakamla formatla
            formatted_df = desc_df.style.format("{:.2f}")
            
            # Tabloyu gÃ¶ster
            st.dataframe(formatted_df)
                # Button zum Fortfahren
        if st.button("Weiter zur Spaltenauswahl"):
            activate_component("select_columns")
            st.rerun()
    else:
        st.warning("Bitte laden Sie zuerst Daten.")
        if st.button("ZurÃ¼ck zum Datenimport"):
            activate_component("data_import")
            st.experimental_rerun()

# 3. Spalten auswÃ¤hlen
elif st.session_state.active_components["select_columns"]:
    st.header("3. Datenbereinigung")
    
    if st.session_state.data is not None:
        # Zeige alle verfÃ¼gbaren Spalten an
        st.write("VerfÃ¼gbare Spalten:")
        st.dataframe(pd.DataFrame({
            'Spaltenname': st.session_state.data.columns,
            'Datentyp': st.session_state.data.dtypes.values
        }))
        
        # Mehrfachauswahl fÃ¼r Features
        st.subheader("Features auswÃ¤hlen")
        feature_cols = st.multiselect(
            "WÃ¤hlen Sie die Feature-Spalten aus:",
            options=[col for col in st.session_state.data.columns],
            default=[col for col in st.session_state.data.columns if col != 'target']
        )
        
        # Zielspaltenwahl
        st.subheader("Zielvariable auswÃ¤hlen")
        target_col = st.selectbox(
            "WÃ¤hlen Sie die Zielspalte aus:",
            options=st.session_state.data.columns.tolist(),
            index=st.session_state.data.columns.get_loc('target') if 'target' in st.session_state.data.columns else 0
        )
        
        if st.button("Spalten Ã¼bernehmen"):
            if not feature_cols:
                st.error("Bitte wÃ¤hlen Sie mindestens eine Feature-Spalte aus.")
            else:
                st.session_state.selected_columns = {
                    'features': feature_cols,
                    'target': target_col
                }
                st.success(f"{len(feature_cols)} Feature-Spalten und 1 Zielspalte ausgewÃ¤hlt!")
                
                # Zeige ausgewÃ¤hlte Spalten an
                selected_data = st.session_state.data[feature_cols + [target_col]]
                st.write("Vorschau der ausgewÃ¤hlten Spalten:")
                st.dataframe(selected_data.head())
                
                # Button zum Fortfahren
                if st.button("Weiter zum Daten-Sampling"):
                    activate_component("data_sampling")
                    st.experimental_rerun()
    else:
        st.warning("Bitte laden Sie zuerst Daten.")
        if st.button("ZurÃ¼ck zum Datenimport"):
            activate_component("data_import")
            st.experimental_rerun()

# 4. Daten-Sampling
elif st.session_state.active_components["data_sampling"]:
    st.header("4. Daten-Sampling")
    
    if st.session_state.selected_columns is not None:
        features = st.session_state.selected_columns['features']
        target = st.session_state.selected_columns['target']
        
        # Bereite Daten vor
        selected_data = st.session_state.data[features + [target]]
        
        # Optionen fÃ¼r Daten-Sampling
        st.subheader("Daten aufteilen")
        
        col1, col2 = st.columns(2)
        with col1:
            test_size = st.slider("Testdaten-Anteil (%)", 10, 50, 30) / 100
        with col2:
            random_state = 42
            
        # Stratifiziertes Sampling bei Klassifikationsproblemen
        st.markdown("**Stratifiziertes Sampling ist standardmÃ¤ÃŸig aktiviert.**")
        stratify_option = True  # Immer aktiviert
        
        if st.button("Daten aufteilen"):
            X = selected_data[features]
            y = selected_data[target]
            
            # PrÃ¼fe, ob wir stratifizieren sollten
            stratify_val = y if stratify_option else None
            
            # Daten aufteilen
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=stratify_val
            )
            
            # Speichere aufgeteilte Daten im Session State
            st.session_state.X_train = X_train
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_test = y_test
            st.session_state.sampled_data = True
            
            # Zeige Zusammenfassung
            st.success("Daten erfolgreich aufgeteilt!")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"Trainingsdaten: {X_train.shape[0]} Beispiele")
                st.dataframe(pd.concat([X_train, y_train], axis=1).head())
            with col2:
                st.write(f"Testdaten: {X_test.shape[0]} Beispiele")
                st.dataframe(pd.concat([X_test, y_test], axis=1).head())
            
            # Zeige Verteilung der Klassen
            if y.dtype == 'object' or y.dtype == 'category':
                st.subheader("Klassenverteilung")
                col1, col2 = st.columns(2)
                with col1:
                    st.write("Training:")
                    train_dist = y_train.value_counts().reset_index()
                    train_dist.columns = [target, 'Anzahl']
                    train_fig = px.pie(train_dist, values='Anzahl', names=target, title="Trainingsdaten")
                    st.plotly_chart(train_fig, use_container_width=True)
                with col2:
                    st.write("Test:")
                    test_dist = y_test.value_counts().reset_index()
                    test_dist.columns = [target, 'Anzahl']
                    test_fig = px.pie(test_dist, values='Anzahl', names=target, title="Testdaten")
                    st.plotly_chart(test_fig, use_container_width=True)
                
                # Button zum Fortfahren
                if st.button("Weiter zur Modellierung"):
                    activate_component("modeling")
                    st.experimental_rerun()
    else:
        st.warning("Bitte wÃ¤hlen Sie zuerst die Spalten aus.")
        if st.button("ZurÃ¼ck zur Spaltenauswahl"):
            activate_component("select_columns")
            st.experimental_rerun()
# 5. Verbesserter Modellierungsabschnitt mit Orange-Ã¤hnlicher FunktionalitÃ¤t
elif st.session_state.active_components["modeling"]:
    st.header("5. Modellierung", divider="orange")
    
    if st.session_state.sampled_data:
        # Initialisiere ein Dictionary fÃ¼r mehrere Modelle, falls nicht vorhanden
        if 'models' not in st.session_state:
            st.session_state.models = {}
        
        # Informationsbereich: Trainingsstatistik
        st.info(f"Trainings-/Testdaten Split: {len(st.session_state.X_train)} Training / {len(st.session_state.X_test)} Test")
        
        # Dashboard fÃ¼r Trainingsstatistik
        st.write("#### Dataset-Statistik")
        col1, col2, col3 = st.columns(3)
        col1.metric("Trainingsdaten", f"{len(st.session_state.X_train)}")
        col2.metric("Testdaten", f"{len(st.session_state.X_test)}")
        col3.metric("Gesamtdatensatz", f"{len(st.session_state.data)}")
        
        # Zeige bereits trainierte Modelle an
        if st.session_state.models:
            st.subheader("Trainierte Modelle")
            model_df = pd.DataFrame([
                {
                    "Modell": model_id,
                    "Typ": model_info['type'],
                    "Parameter": str(model_info['params']),
                    "Datenpunkte": len(model_info['full_predictions']),
                    "Accuracy (Test)": f"{accuracy_score(st.session_state.y_test, model_info['test_predictions']):.4f}"
                }
                for model_id, model_info in st.session_state.models.items()
            ])
            st.dataframe(model_df, use_container_width=True)
        
        # Orange-Style Tabs fÃ¼r unterschiedliche Learner
        learner_tab = st.tabs(["Learner",])[0]
        
        with learner_tab:
            # Modellauswahl mit Orange-Ã¤hnlichem Styling
            model_type = st.radio(
                "Lernalgorithmus auswÃ¤hlen",
                ["k-Nearest Neighbors (kNN)", "Entscheidungsbaum (Tree)", "Logistische Regression"],
                horizontal=True
            )
            
            # Eindeutige Modell-ID generieren
            with st.form(key="model_form"):
                custom_model_name = st.text_input("Modellname (zur Identifikation)"
                          )
    
                
                # Hyperparameter basierend auf Modelltyp
                if model_type == "k-Nearest Neighbors (kNN)":
                    st.subheader("kNN Hyperparameter")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        n_neighbors = st.slider("Anzahl der Nachbarn (k)", 1, 20, 3)
                    with col2:
                        weights = st.selectbox(
                            "Gewichtungsmethode",
                            options=["uniform", "distance"],
                            index=0,
                            help="'uniform': Alle Nachbarn gleich gewichtet, 'distance': Nach Abstand gewichtet"
                        )
                    with col3:
                        metric = st.selectbox(
                            "Distanzmetrik",
                            options=["euclidean", "manhattan", "chebyshev", "minkowski"],
                            index=0,
                            help="Metrik zur Berechnung der Distanz zwischen den Punkten"
                        )
                    
                    # Preprocessing-Optionen, wie in Orange
                    st.subheader("Preprocessing")
                    standardize = st.checkbox("Daten standardisieren (empfohlen fÃ¼r kNN)", value=True)
                    
                elif model_type == "Entscheidungsbaum (Tree)":
                    st.subheader("Entscheidungsbaum Hyperparameter")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        max_depth = st.slider("Maximale Tiefe", 1, 100, 100,
                                            help="Maximale Tiefe des Baums. 100 bedeutet praktisch unbegrenzt.")
                        min_samples_split = st.slider("Min. Samples fÃ¼r Split", 2, 20, 5)
                    with col2:
                        min_samples_leaf = st.slider("Min. Samples in BlÃ¤ttern", 1, 20, 2)
                        # Split-Kriterium seÃ§eneÄŸini kaldÄ±rÄ±ldÄ± ve sabit deÄŸere ayarlandÄ±
                        criterion = "gini"  # Daima "gini" olarak ayarlandÄ±
                    
                    # Orange-spezifische Baumoptionen
                    binary_splits = st.checkbox("BinÃ¤re Splits erzwingen", value=True)
                    limit_depth = st.checkbox("Baumtiefe begrenzen", value=False)
                    if limit_depth:
                        max_depth = st.slider("Max. Tiefe", 1, 50, 10)
                    else:
                        max_depth = None
                    limit_majority = st.checkbox("Stop-Kriterium: Mehrheitsklasse", value=True)
                    if limit_majority:
                        majority_threshold = st.slider("Schwellenwert (%)", 50, 100, 95)
                    else:
                        majority_threshold = 100
                
                elif model_type == "Logistische Regression":  # Logistische Regression
                    st.subheader("Logistische Regression Hyperparameter")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        C = st.slider("RegularisierungsstÃ¤rke C", 0.01, 10.0, 1.0, step=0.01,
                                    help="Kleinere Werte bedeuten stÃ¤rkere Regularisierung")
                        solver = st.selectbox(
                            "Solver",
                            options=["lbfgs", "liblinear", "newton-cg", "sag", "saga"],
                            index=0
                        )
                    with col2:
                        penalty = st.selectbox(
                            "Regularisierung",
                            options=["l2", "l1", "elasticnet", "none"],
                            index=0,
                            help="Regularisierungstyp (abhÃ¤ngig vom gewÃ¤hlten Solver)"
                        )
                        max_iter = st.slider("Max. Iterationen", 100, 1000, 100, step=50)
                    
                    # Preprocessing-Optionen
                    st.subheader("Preprocessing")
                    standardize = st.checkbox("Daten standardisieren (empfohlen)", value=True)
                
                # Orange-Style: Validierungsoptionen
                st.subheader("Validation")
                validation_method = st.selectbox(
                    "Validierungsmethode",
                    options=["Test on Train Data", "Test on Test Data"],
                    index=0
                )
                
                # Modell-Training
                submit_button = st.form_submit_button("Modell anwenden")
                
                if submit_button:
                    model_name = custom_model_name
                    with st.spinner("Lernalgorithmus wird trainiert..."):
                        # Daten vorbereiten
                        X_train = st.session_state.X_train
                        y_train = st.session_state.y_train
                        X_test = st.session_state.X_test
                        y_test = st.session_state.y_test
                        
                        # Orange-Stil: Alle Daten zusammenfassen fÃ¼r komplette Vorhersagen
                        features = st.session_state.selected_columns['features']
                        target = st.session_state.selected_columns['target']
                        
                        # Gesamter Datensatz fÃ¼r vollstÃ¤ndige Vorhersagen
                        X_full = st.session_state.data[features]
                        y_full = st.session_state.data[target]
                        
                        # Modellspezifische Verarbeitung und Training
                        if model_type == "k-Nearest Neighbors (kNN)":
                            # Standardisierung falls ausgewÃ¤hlt
                            if standardize:
                                scaler = StandardScaler()
                                X_train_scaled = scaler.fit_transform(X_train)
                                X_test_scaled = scaler.transform(X_test)
                                X_full_scaled = scaler.transform(X_full)
                                
                                # Umwandlung in DataFrame fÃ¼r spÃ¤tere Verwendung
                                X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
                                X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
                                X_full_scaled = pd.DataFrame(X_full_scaled, columns=X_full.columns)
                            else:
                                X_train_scaled = X_train
                                X_test_scaled = X_test
                                X_full_scaled = X_full
                                scaler = None
                            
                            # Modell erstellen und trainieren
                            model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)
                            model.fit(X_train_scaled, y_train)
                            
                            # Vorhersagen
                            train_predictions = model.predict(X_train_scaled)
                            test_predictions = model.predict(X_test_scaled)
                            full_predictions = model.predict(X_full_scaled)
                            
                            # Modell-Metadaten
                            model_metadata = {
                                'type': 'kNN',
                                'instance': model,
                                'standardize': standardize,
                                'scaler': scaler,
                                'params': {'n_neighbors': n_neighbors, 'weights': weights, 'metric': metric},
                                'X_train_processed': X_train_scaled,
                                'X_test_processed': X_test_scaled,
                                'X_full_processed': X_full_scaled,
                            }
                            
                        elif model_type == "Entscheidungsbaum (Tree)":
                            # Modell erstellen und trainieren
                            tree_depth = max_depth if limit_depth else None
                            model = DecisionTreeClassifier(
                                max_depth=tree_depth,
                                criterion=criterion,
                                min_samples_split=min_samples_split,
                                min_samples_leaf=min_samples_leaf,
                                random_state=42
                            )
                            model.fit(X_train, y_train)
                            
                            # Vorhersagen
                            train_predictions = model.predict(X_train)
                            test_predictions = model.predict(X_test)
                            full_predictions = model.predict(X_full)
                            
                            # Modell-Metadaten
                            model_metadata = {
                                'type': 'DecisionTree',
                                'instance': model,
                                'standardize': False,
                                'params': {
                                    'max_depth': tree_depth,
                                    'criterion': criterion,
                                    'min_samples_split': min_samples_split,
                                    'min_samples_leaf': min_samples_leaf,
                                    'binary_splits': binary_splits,
                                    'majority_threshold': f"{majority_threshold}%" if limit_majority else "N/A"
                                },
                                'X_train_processed': X_train,
                                'X_test_processed': X_test,
                                'X_full_processed': X_full,
                            }
                            
                        else:  # Logistische Regression
                            # Standardisierung
                            if standardize:
                                scaler = StandardScaler()
                                X_train_scaled = scaler.fit_transform(X_train)
                                X_test_scaled = scaler.transform(X_test)
                                X_full_scaled = scaler.transform(X_full)
                                
                                # Umwandlung in DataFrame fÃ¼r spÃ¤tere Verwendung
                                X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
                                X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
                                X_full_scaled = pd.DataFrame(X_full_scaled, columns=X_full.columns)
                            else:
                                X_train_scaled = X_train
                                X_test_scaled = X_test
                                X_full_scaled = X_full
                                scaler = None
                            
                            # Modell erstellen und trainieren
                            model = LogisticRegression(
                                C=C,
                                penalty=penalty,
                                solver=solver,
                                max_iter=max_iter,
                                random_state=42,
                                multi_class='auto'
                            )
                            model.fit(X_train_scaled, y_train)
                            
                            # Vorhersagen
                            train_predictions = model.predict(X_train_scaled)
                            test_predictions = model.predict(X_test_scaled)
                            full_predictions = model.predict(X_full_scaled)
                            
                            # Modell-Metadaten
                            model_metadata = {
                                'type': 'LogisticRegression',
                                'instance': model,
                                'standardize': standardize,
                                'scaler': scaler,
                                'params': {'C': C, 'penalty': penalty, 'solver': solver, 'max_iter': max_iter},
                                'X_train_processed': X_train_scaled,
                                'X_test_processed': X_test_scaled,
                                'X_full_processed': X_full_scaled,
                            }
                        
                        # Gemeinsame Modell-Speicherung fÃ¼r alle Typen
                        model_metadata.update({
                            'train_predictions': train_predictions,
                            'test_predictions': test_predictions,
                            'full_predictions': full_predictions,
                            'predictions': test_predictions,  # FÃ¼r KompatibilitÃ¤t mit altem Code
                            'y_full': y_full,  # Speichern der tatsÃ¤chlichen Werte fÃ¼r den gesamten Datensatz
                            'y_train': y_train,
                            'y_test': y_test,
                            'validation_method': validation_method
                        })
                        
                        # Modell speichern
                        st.session_state.models[model_name] = model_metadata
                        
                        # Aktuelles Modell setzen fÃ¼r die Evaluation
                        st.session_state.current_model = model_name
                        
                        # Orange-Style Zusammenfassung
                        st.success(f"{model_type}-Modell '{model_name}' erfolgreich trainiert!")
                        
                        # Orange-Style: Zusammenfassung direkt nach dem Training anzeigen
                        acc_train = accuracy_score(y_train, train_predictions)
                        acc_test = accuracy_score(y_test, test_predictions)
                        
                        eval_col1, eval_col2 = st.columns(2)
                        eval_col1.metric("Trainingsgenauigkeit", f"{acc_train:.4f}")
                        eval_col2.metric("Testgenauigkeit", f"{acc_test:.4f}", 
                                       delta=f"{acc_test - acc_train:.4f}")
                        
                        # Bei EntscheidungsbÃ¤umen: Feature-Importance anzeigen
                        if model_type == "Entscheidungsbaum (Tree)":
                            st.subheader("Feature-Importance")
                            feature_importance = pd.DataFrame({
                                'Feature': X_train.columns,
                                'Importance': model.feature_importances_
                            }).sort_values('Importance', ascending=False)
                            
                            fig = px.bar(
                                feature_importance, 
                                x='Feature', 
                                y='Importance',
                                title=f"Feature-Importance des Entscheidungsbaums '{model_name}'"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        if model_type == "Logistische Regression" and penalty != "none":
                            st.subheader("Koeffizienten")
                            coef_df = pd.DataFrame({
                                'Feature': X_train.columns,
                                'Koeffizient': model.coef_[0] if model.coef_.shape[0] == 1 else model.coef_.mean(axis=0)
                            }).sort_values('Koeffizient', ascending=False)
                            
                            fig = px.bar(
                                coef_df, 
                                x='Feature', 
                                y='Koeffizient',
                                title=f"Koeffizienten der Logistischen Regression '{model_name}'"
                            )
                            st.plotly_chart(fig, use_container_width=True)
      # Save Model Widget (Orange-Style)
    if st.session_state.models:
        save_expander = st.expander("Modell speichern (Save Model)", expanded=False)
        with save_expander:
            st.write("#### ðŸ’¾ Modell fÃ¼r spÃ¤tere Verwendung speichern")
            
            # Modell zum Speichern auswÃ¤hlen
            model_to_save = st.selectbox(
                "Modell zum Speichern auswÃ¤hlen",
                options=list(st.session_state.models.keys())
            )
            
            # Speicheroption
            if st.button("Modell exportieren"):
             import pickle

            # TÃ¼m gerekli bilgileri iÃ§eren bir model paketi oluÅŸtur
             model_package = {
                'model': st.session_state.models[model_to_save]['instance'],
                'scaler': st.session_state.models[model_to_save].get('scaler', None),  # .get() metodu ile gÃ¼venli eriÅŸim
                'standardize': st.session_state.models[model_to_save].get('standardize', False),  # .get() metodu
                'feature_names': st.session_state.models[model_to_save]['X_train_processed'].columns.tolist()
            }

            # TÃ¼m paketi serialize et
             st.session_state.serialized_model = pickle.dumps(model_package)
             st.session_state.model_to_save = model_to_save
            # Download-Button anzeigen
              # EÄŸer model export edildiyse, indirme butonunu gÃ¶ster
        if st.session_state.serialized_model:
            st.download_button(
                label="Modell herunterladen (.pkl)",
                data=st.session_state.serialized_model,
                file_name=f"{st.session_state.model_to_save}.pkl",
                mime="application/octet-stream"
            )

            st.success(f"Modell '{st.session_state.model_to_save}' kann jetzt heruntergeladen werden.")
            st.info("Dieses Modell kann spÃ¤ter mit dem Prediction-Widget wieder geladen werden.")
                    # Button zum Fortfahren zur Evaluation
        if st.session_state.models:
            if st.button("Weiter zur Evaluation", type="primary"):
                activate_component("evaluation")
                st.rerun()
                
    else:
        st.warning("Bitte fÃ¼hren Sie zuerst das Daten-Sampling durch.")
        if st.button("ZurÃ¼ck zum Daten-Sampling"):
            activate_component("data_sampling")
            st.rerun()
# 6. SadeleÅŸtirilmiÅŸ Model DeÄŸerlendirme (Test and Score)
elif st.session_state.active_components["evaluation"]:
    st.header("6. Modell-Evaluation", divider="orange")
    
    if st.session_state.models:
        # Ana sayfa bir sekmeli arayÃ¼z oluÅŸturun: karÅŸÄ±laÅŸtÄ±rma ve detaylar
        main_tab1, main_tab2 = st.tabs(["Modell Vergleich", "Modell Details"])
        
        with main_tab1:
            st.subheader("Modellvergleich")
            
            # KarÅŸÄ±laÅŸtÄ±rÄ±lacak modelleri seÃ§in - maksimum 2 model
            model_options = list(st.session_state.models.keys())
            
            col1, col2 = st.columns(2)
            with col1:
                model1 = st.selectbox("Modell 1", model_options, 
                                    index=0 if model_options else 0,
                                    key="model1_select")
            with col2:
                remaining_models = [m for m in model_options if m != model1]
                model2 = st.selectbox("Modell 2", 
                                    options=remaining_models,
                                    index=0 if remaining_models else 0,
                                    key="model2_select")
            
            if len(model_options) > 1:
                # Veri setiyle deÄŸerlendirme
                test_or_train = st.radio(
                    "Datensatz wÃ¤hlen",
                    ["Testdaten", "Trainingsdaten"],
                    horizontal=True
                )
                
                # SeÃ§ilen modeller hakkÄ±nda bilgi alÄ±n
                model1_info = st.session_state.models[model1]
                
                if model2 in st.session_state.models:
                    model2_info = st.session_state.models[model2]
                    
                    # DoÄŸru deÄŸerlendirme verilerini belirleyin
                    if test_or_train == "Testdaten":
                        X_data = st.session_state.X_test
                        y_true = st.session_state.y_test
                        y_pred1 = model1_info['test_predictions']
                        y_pred2 = model2_info['test_predictions']
                    else:
                        X_data = st.session_state.X_train
                        y_true = st.session_state.y_train
                        y_pred1 = model1_info['train_predictions']
                        y_pred2 = model2_info['train_predictions']
                    
                    # KÄ±yaslama metriklerini hesaplayÄ±n
                    metrics = {
                        "Genauigkeit (Accuracy)": [
                            accuracy_score(y_true, y_pred1),
                            accuracy_score(y_true, y_pred2)
                        ],
                         "Precision": [
                            precision_score(y_true, y_pred1, average='weighted', zero_division=0),
                            precision_score(y_true, y_pred2, average='weighted', zero_division=0)
                        ],
                        "Recall": [
                            recall_score(y_true, y_pred1, average='weighted', zero_division=0),
                            recall_score(y_true, y_pred2, average='weighted', zero_division=0)
                        ],
                        "F1-Score": [
                            f1_score(y_true, y_pred1, average='weighted', zero_division=0),
                            f1_score(y_true, y_pred2, average='weighted', zero_division=0)
                        ],
                    }
                    
                    # 1. Metrikleri gÃ¶rselleÅŸtirin
                    st.write("##### Performance-Metriken im Vergleich")
                    metrics_df = pd.DataFrame(metrics, index=[model1, model2]).T
                    st.dataframe(metrics_df.style.format("{:.4f}"), use_container_width=True)
                    
                    # 2. Metrikleri grafik olarak karÅŸÄ±laÅŸtÄ±rÄ±n
                    metrics_melted = pd.melt(
                        metrics_df.reset_index(),
                        id_vars='index',
                        var_name='Modell',
                        value_name='Wert'
                    )
                    metrics_melted['Wert'] = pd.to_numeric(metrics_melted['Wert'], errors='coerce')
                    metrics_melted = metrics_melted.dropna(subset=['Wert'])
                    fig = px.bar(
                        metrics_melted, 
                        x='index', 
                        y='Wert', 
                        color='Modell', 
                        barmode='group',
                        title="Modellvergleich",
                        labels={'index': 'Metrik', 'Wert': 'Wert'},
                        height=400
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # 3. Confusion Matrices
                    st.write("##### Confusion Matrices")
                    
                    cm_col1, cm_col2 = st.columns(2)
                    
                    with cm_col1:
                        st.write(f"**{model1}**")
                        cm1 = confusion_matrix(y_true, y_pred1)
                        classes = sorted(y_true.unique())
                        
                        fig1, ax1 = plt.subplots(figsize=(4, 3))
                        sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', 
                                xticklabels=classes, yticklabels=classes)
                        plt.title(f'Confusion Matrix - {model1}')
                        plt.ylabel('TatsÃ¤chliche Klasse')
                        plt.xlabel('Vorhergesagte Klasse')
                        st.pyplot(fig1)
                    
                    with cm_col2:
                        st.write(f"**{model2}**")
                        cm2 = confusion_matrix(y_true, y_pred2)
                        
                        fig2, ax2 = plt.subplots(figsize=(4, 3))
                        sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues', 
                                xticklabels=classes, yticklabels=classes)
                        plt.title(f'Confusion Matrix - {model2}')
                        plt.ylabel('TatsÃ¤chliche Klasse')
                        plt.xlabel('Vorhergesagte Klasse')
                        st.pyplot(fig2)
                else:
                    st.warning("Bitte wÃ¤hlen Sie zwei verschiedene Modelle fÃ¼r den Vergleich aus.")
            else:
                st.warning("Sie benÃ¶tigen mindestens zwei trainierte Modelle fÃ¼r einen Vergleich.")
        
        with main_tab2:
            st.subheader("Modelldetails")
            
            # DetaylÄ± inceleme iÃ§in model seÃ§in
            detailed_model = st.selectbox(
                "Modell fÃ¼r detaillierte Analyse",
                options=model_options,
                index=0 if model_options else 0
            )
            
            if detailed_model:
                model_info = st.session_state.models[detailed_model]
                
                # Modeli yorumlayÄ±n
                st.write(f"##### {detailed_model} ({model_info['type']})")
                
                # Modelin parametrelerini gÃ¶ster
                st.write("**Parameter:**")
                params_df = pd.DataFrame([model_info['params']])
                st.dataframe(params_df.T.rename(columns={0: "Wert"}))
                
                # Veri setini seÃ§in
                test_or_train_detail = st.radio(
                    "Datensatz fÃ¼r Detail-Analyse",
                    ["Testdaten", "Trainingsdaten"],
                    horizontal=True,
                    key="detail_data_choice"
                )
                
                # DoÄŸru deÄŸerlendirme verilerini belirleyin
                if test_or_train_detail == "Testdaten":
                    X_data = st.session_state.X_test
                    y_true = st.session_state.y_test
                    y_pred = model_info['test_predictions']
                else:
                    X_data = st.session_state.X_train
                    y_true = st.session_state.y_train
                    y_pred = model_info['train_predictions']
                
                # Metrikler, Confusion Matrix ve SÄ±nÄ±flandÄ±rma Raporu iÃ§in sekme
                det_tab1, det_tab2, det_tab3 = st.tabs(["Metriken", "Confusion Matrix", "Klassifikationsbericht"])
                
                with det_tab1:
                    # DetaylÄ± metrikler
                    acc = accuracy_score(y_true, y_pred)
                    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)
                    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)
                    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("Accuracy", f"{acc:.4f}")
                    col2.metric("Precision", f"{prec:.4f}")
                    col3.metric("Recall", f"{rec:.4f}")
                    col4.metric("F1-Score", f"{f1:.4f}")
                
                with det_tab2:
                    # Confusion Matrix
                    cm = confusion_matrix(y_true, y_pred)
                    classes = sorted(y_true.unique())
                    
                    # Normalize option
                    normalize_cm = st.checkbox("Confusion Matrix normalisieren", value=False)
                    
                    # Plot Confusion Matrix
                    fig, ax = plt.subplots(figsize=(8, 6))
                    
                    if normalize_cm:
                        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
                        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', 
                                   xticklabels=classes, yticklabels=classes)
                        plt.title(f'Normalisierte Confusion Matrix - {detailed_model}')
                    else:
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                                   xticklabels=classes, yticklabels=classes)
                        plt.title(f'Confusion Matrix - {detailed_model}')
                    
                    plt.ylabel('TatsÃ¤chliche Klasse')
                    plt.xlabel('Vorhergesagte Klasse')
                    st.pyplot(fig)
                
                with det_tab3:
                    # SÄ±nÄ±flandÄ±rma raporu
                    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
                    report_df = pd.DataFrame(report).transpose()
                    
                    # Formatlamak
                    st.dataframe(report_df.style.format({
                        'precision': '{:.4f}',
                        'recall': '{:.4f}',
                        'f1-score': '{:.4f}',
                        'support': '{:.0f}'
                    }))
                
                # En iyi modeli Ã¶nerebiliriz
                if test_or_train_detail == "Testdaten":
                    st.info(f"Hinweis: Um dieses Modell fÃ¼r Prediction zu verwenden, speichern Sie es bitte in der Modellierungskomponente.")
        
        # Navigation buttons
        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ZurÃ¼ck zur Modellierung"):
                activate_component("modeling")
                st.rerun()
        
        with col2:
            if st.button("Weiter zur Prediction", type="primary"):
                activate_component("prediction")
                st.rerun()
    
    else:
        st.warning("Es wurden noch keine Modelle trainiert. Bitte gehen Sie zurÃ¼ck zum Modellierungs-Abschnitt.")
        if st.button("ZurÃ¼ck zur Modellierung"):
            activate_component("modeling")
            st.rerun()
        
        # Button zum Neustart
        if st.button("Workflow neu starten"):
            activate_component("data_import")
            st.rerun()
            
        # Button zur RÃ¼ckkehr zur Modellierung
        if st.button("ZurÃ¼ck zur Modellierung (weitere Modelle trainieren)"):
            activate_component("modeling")
            st.rerun()
        if st.button("Weiter zur Prediction", type="primary"):
            activate_component("prediction")
            st.rerun()
        else:
         st.warning("Bitte trainieren Sie zuerst ein Modell.")
        if st.button("ZurÃ¼ck zur Modellierung"):
            activate_component("modeling")
# 7. Prediction Komponente (Orange-Style Modell-Laden Workflow)
# 7. Prediction Komponente (2-AdÄ±mlÄ± YapÄ±)
elif st.session_state.active_components["prediction"]:
    st.header("7. Prediction", divider="orange")
    
    # Initialisierung des Session States fÃ¼r Prediction
    if 'loaded_models' not in st.session_state:
        st.session_state.loaded_models = {}
    if 'prediction_dataset' not in st.session_state:
        st.session_state.prediction_dataset = None
    if 'prediction_step' not in st.session_state:
        st.session_state.prediction_step = "preparation"
    if 'prediction_columns' not in st.session_state:
        st.session_state.prediction_columns = {}
    
    # Progress Bar fÃ¼r die Schritte
    progress_steps = ["Vorbereitung", "Ergebnisse"]
    current_step_index = 0 if st.session_state.prediction_step == "preparation" else 1
    
    # Fortschrittsanzeige
    st.progress((current_step_index + 1) / len(progress_steps))
    st.write(f"**Schritt {current_step_index + 1} von {len(progress_steps)}: {progress_steps[current_step_index]}**")
    
    # SCHRITT 1: VORBEREITUNG
    if st.session_state.prediction_step == "preparation":
        st.subheader("Schritt 1: Vorbereitung")
        st.write("Laden Sie Ihre Modelle und DatensÃ¤tze, und konfigurieren Sie die Spalten.")
        
        # Hauptbereich in 3 Spalten aufteilen
        col1, col2, col3 = st.columns([1, 1, 1])
        
        # Spalte 1: Modelle laden
        with col1:
            st.write("#### ðŸ“‚ Modelle laden")
            
            # Modell 1 laden
            with st.expander("Modell 1", expanded=True):
                load_model1 = st.file_uploader("Modell 1 (.pkl)", type="pkl", key="model1_uploader")
                if load_model1 is not None:
                    try:
                        import pickle
                        model1 = pickle.load(load_model1)
                        model_name = load_model1.name
                        st.session_state.loaded_models[model_name] = model1
                        st.success(f"âœ… {model_name}")
                    except Exception as e:
                        st.error(f"âŒ Fehler: {str(e)}")
            
            # Modell 2 laden
            with st.expander("Modell 2", expanded=False):
                load_model2 = st.file_uploader("Modell 2 (.pkl)", type="pkl", key="model2_uploader")
                if load_model2 is not None:
                    try:
                        import pickle
                        model2 = pickle.load(load_model2)
                        model_name = load_model2.name
                        st.session_state.loaded_models[model_name] = model2
                        st.success(f"âœ… {model_name}")
                    except Exception as e:
                        st.error(f"âŒ Fehler: {str(e)}")
            
            # Aktuell geladene Modelle anzeigen
            if st.session_state.loaded_models:
                st.write("**Geladene Modelle:**")
                for model_name in st.session_state.loaded_models.keys():
                    st.write(f"â€¢ {model_name}")
        
        # Spalte 2: Datensatz laden
        with col2:
            st.write("#### ðŸ“Š Datensatz laden")
            
            uploaded_file = st.file_uploader("Neuen Datensatz laden (.csv)", type="csv")
            if uploaded_file is not None:
                try:
                    new_data = pd.read_csv(uploaded_file)
                    st.session_state.prediction_dataset = new_data
                    st.success(f"âœ… Datensatz geladen")
                    st.write(f"**GrÃ¶ÃŸe:** {new_data.shape[0]} Zeilen, {new_data.shape[1]} Spalten")
                    
                    # Kleine Vorschau
                    with st.expander("Datensatz-Vorschau", expanded=False):
                        st.dataframe(new_data.head(3))
                        
                except Exception as e:
                    st.error(f"âŒ Fehler beim Laden: {str(e)}")
            
            # Aktueller Datensatz Status
            if st.session_state.prediction_dataset is not None:
                st.write("**Aktueller Datensatz:**")
                st.write(f"â€¢ {st.session_state.prediction_dataset.shape[0]} Zeilen")
                st.write(f"â€¢ {st.session_state.prediction_dataset.shape[1]} Spalten")
        
        # Spalte 3: Spalten konfigurieren
        with col3:
            st.write("#### ðŸ” Spalten konfigurieren")
            
            if st.session_state.prediction_dataset is not None:
                all_columns = st.session_state.prediction_dataset.columns.tolist()
                
                # Klassenvariable auswÃ¤hlen
                target_column = st.selectbox(
                    "Klassenvariable (Target)",
                    options=all_columns,
                    index=len(all_columns)-1 if len(all_columns) > 0 else 0
                )
                
                # Features auswÃ¤hlen
                available_features = [col for col in all_columns if col != target_column]
                feature_columns = st.multiselect(
                    "Features auswÃ¤hlen",
                    options=available_features,
                    default=available_features[:5] if len(available_features) > 5 else available_features
                )
                
                # Konfiguration speichern
                if st.button("âœ… Konfiguration Ã¼bernehmen", type="primary"):
                    st.session_state.prediction_columns = {
                        'target': target_column,
                        'features': feature_columns
                    }
                    st.success("Spalten konfiguriert!")
            else:
                st.info("Laden Sie zuerst einen Datensatz.")
        
# Scatter Plot Visualization (NEU HINZUGEFÃœGT)
        if (st.session_state.prediction_dataset is not None and 
            st.session_state.prediction_columns and 
            len(st.session_state.prediction_columns.get('features', [])) >= 2):
            
            st.markdown("---")
            st.subheader("ðŸ“ˆ Datenvisualisierung")
            
            # Scatter Plot Parameter auswÃ¤hlen
            col_viz1, col_viz2 = st.columns(2)
            
            with col_viz1:
                x_axis = st.selectbox(
                    "X-Achse",
                    options=st.session_state.prediction_columns['features'],
                    key="scatter_x"
                )
            
            with col_viz2:
                y_axis = st.selectbox(
                    "Y-Achse", 
                    options=[col for col in st.session_state.prediction_columns['features'] if col != x_axis],
                    key="scatter_y"
                )
            
            # Scatter Plot erstellen
            if x_axis and y_axis:
                try:
                    import matplotlib.pyplot as plt
                    import seaborn as sns
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    # Daten fÃ¼r den Plot vorbereiten
                    plot_data = st.session_state.prediction_dataset.copy()
                    target_col = st.session_state.prediction_columns['target']
                    
                    # Scatter plot mit Farbe basierend auf Target-Variable
                    if target_col in plot_data.columns:
                        # PrÃ¼fen ob Target numerisch oder kategorisch ist
                        if plot_data[target_col].dtype in ['object', 'category'] or plot_data[target_col].nunique() <= 10:
                            # Kategorische Target-Variable mit spezifischen Farben
                            unique_targets = plot_data[target_col].unique()
                            
                            # Spezifische Farbzuordnung fÃ¼r die Kategorien
                            color_mapping = {
                                'broken': 'lightblue',     # aÃ§Ä±k mavi
                                'heavyload': 'red',        # kÄ±rmÄ±zÄ±  
                                'good': 'darkblue'         # koyu mavi
                            }
                            
                            for target_val in unique_targets:
                                mask = plot_data[target_col] == target_val
                                # Spezifische Farbe verwenden, falls verfÃ¼gbar, sonst Standardfarbe
                                color = color_mapping.get(str(target_val).lower(), 'gray')
                                
                                ax.scatter(plot_data.loc[mask, x_axis], 
                                         plot_data.loc[mask, y_axis],
                                         c=color, 
                                         label=f'{target_col}: {target_val}',
                                         alpha=0.7, s=60)
                            ax.legend()
                        else:
                            # Numerische Target-Variable
                            scatter = ax.scatter(plot_data[x_axis], plot_data[y_axis], 
                                               c=plot_data[target_col], 
                                               cmap='viridis', alpha=0.6, s=50)
                            plt.colorbar(scatter, ax=ax, label=target_col)
                    else:
                        # Kein Target verfÃ¼gbar - einfacher Scatter Plot
                        ax.scatter(plot_data[x_axis], plot_data[y_axis], 
                                 alpha=0.6, s=50, color='steelblue')
                    
                    ax.set_xlabel(x_axis)
                    ax.set_ylabel(y_axis)
                    ax.set_title(f'Scatter Plot: {x_axis} vs {y_axis}')
                    ax.grid(True, alpha=0.3)
                    
                    # Plot in Streamlit anzeigen
                    st.pyplot(fig)
                    plt.close()
                    
                    
                except Exception as e:
                    st.error(f"âŒ Fehler beim Erstellen des Plots: {str(e)}")
        
        # Status-Check und Weiter-Button
        st.markdown("---")
        
        # Bereitschafts-Check
        ready_conditions = [
            ("Mindestens ein Modell geladen", len(st.session_state.loaded_models) > 0),
            ("Datensatz geladen", st.session_state.prediction_dataset is not None),
            ("Spalten konfiguriert", bool(st.session_state.prediction_columns))
        ]
        
        # Status anzeigen
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.write("**Bereitschafts-Check:**")
            all_ready = True
            for condition, status in ready_conditions:
                icon = "âœ…" if status else "âŒ"
                st.write(f"{icon} {condition}")
                if not status:
                    all_ready = False
        
        with col2:
            if all_ready:
                if st.button("âž¡ï¸ Zu den Ergebnissen", type="primary", use_container_width=True):
                    st.session_state.prediction_step = "results"
                    st.rerun()
            else:
                st.button("âž¡ï¸ Zu den Ergebnissen", disabled=True, use_container_width=True)
                st.caption("VervollstÃ¤ndigen Sie zuerst alle Schritte")
    
    # SCHRITT 2: ERGEBNISSE
    elif st.session_state.prediction_step == "results":
        st.subheader("Schritt 2: Prediction Ergebnisse")
        
        # ZurÃ¼ck-Button
        col1, col2, col3 = st.columns([1, 4, 1])
        with col1:
            if st.button("â¬…ï¸ ZurÃ¼ck zur Vorbereitung"):
                st.session_state.prediction_step = "preparation"
                st.rerun()
        
        # Daten vorbereiten
        X_pred = st.session_state.prediction_dataset[st.session_state.prediction_columns['features']]
        y_true = st.session_state.prediction_dataset[st.session_state.prediction_columns['target']]
        
        # Modell auswÃ¤hlen
        model_options = list(st.session_state.loaded_models.keys())
        selected_model_key = st.selectbox(
            "ðŸ”® Modell fÃ¼r Vorhersage auswÃ¤hlen:",
            options=model_options,
            key="model_selector"
        )
        
        selected_model = st.session_state.loaded_models[selected_model_key]
        
        # Vorhersagen berechnen
        with st.spinner("Berechne Vorhersagen..."):
            try:
                # Model-Typ prÃ¼fen und entsprechend verarbeiten
                if isinstance(selected_model, dict):
                    # Model package structure
                    model = selected_model['model']
                    scaler = selected_model.get('scaler')
                    standardize = selected_model.get('standardize', False)
                    feature_names = selected_model.get('feature_names')
                    
                    # Feature-Namen prÃ¼fen
                    if feature_names:
                        missing_cols = [col for col in feature_names if col not in X_pred.columns]
                        if missing_cols:
                            st.error(f"âŒ Fehlende Spalten: {', '.join(missing_cols)}")
                            st.stop()
                        X_pred = X_pred[feature_names]
                    
                    # Standardisierung anwenden
                    if standardize and scaler:
                        X_pred_processed = scaler.transform(X_pred)
                        y_pred = model.predict(X_pred_processed)
                    else:
                        y_pred = model.predict(X_pred)
                else:
                    # Direktes Model-Objekt
                    y_pred = selected_model.predict(X_pred)
                
                # Ergebnisse vorbereiten
                results_df = X_pred.copy()
                results_df['TatsÃ¤chlich'] = y_true
                results_df['Vorhersage'] = y_pred
                results_df['Korrekt'] = results_df['TatsÃ¤chlich'] == results_df['Vorhersage']
                
                # Ergebnisse in Tabs anzeigen
                tab1, tab2 = st.tabs(["ðŸ“Š Evaluation", "ðŸ“‹ Detailansicht"])
                
                with tab1:
                    # Metriken berechnen
                  
                    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
                    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
                    
                    
                    # Metriken anzeigen
                    col1, col2= st.columns(2)
                    
                    col1.metric("âš–ï¸ Precision", f"{precision:.4f}")
                    col2.metric("ðŸ” Recall", f"{recall:.4f}")
                    
                    # Confusion Matrix
                    st.write("#### ðŸ“Š Confusion Matrix")
                    
                    col1, col2 = st.columns([3, 1])
                    
                    with col2:
                        normalize_cm = st.checkbox("Normalisieren", value=False)
                    
                    with col1:
                        cm = confusion_matrix(y_true, y_pred)
                        classes = sorted(pd.Series(y_true).unique())
                        
                        fig, ax = plt.subplots(figsize=(8, 6))
                        
                        if normalize_cm:
                            cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
                            sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', 
                                      xticklabels=classes, yticklabels=classes, ax=ax)
                            plt.title(f'Normalisierte Confusion Matrix - {selected_model_key}')
                        else:
                            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                                      xticklabels=classes, yticklabels=classes, ax=ax)
                            plt.title(f'Confusion Matrix - {selected_model_key}')
                        
                        plt.ylabel('TatsÃ¤chliche Klasse')
                        plt.xlabel('Vorhergesagte Klasse')
                        st.pyplot(fig)
                    
                    # Klassifikationsbericht
                    
                
                with tab2:
                    # Filter-Optionen
                    display_options = st.radio(
                        "Anzeige filtern:",
                        ["Alle anzeigen", "Nur korrekte Vorhersagen", "Nur falsche Vorhersagen"],
                        horizontal=True
                    )
                    
                    # Daten filtern
                    if display_options == "Nur korrekte Vorhersagen":
                        filtered_df = results_df[results_df['Korrekt']]
                    elif display_options == "Nur falsche Vorhersagen":
                        filtered_df = results_df[~results_df['Korrekt']]
                    else:
                        filtered_df = results_df
                    
                    # Anzahl der Zeilen
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        num_rows = st.slider("Anzahl Zeilen", 5, 100, 20)
                    with col2:
                        if len(filtered_df) > 0:
                            st.write(f"**Ergebnisse:** {len(filtered_df)} von {len(results_df)}")
                        
                    # Ergebnisse anzeigen
                    if len(filtered_df) > 0:
                        st.dataframe(filtered_df.head(num_rows), use_container_width=True)
                    else:
                        st.warning(f"Keine Ergebnisse fÃ¼r '{display_options}'")
                        
            except Exception as e:
                st.error(f"âŒ Fehler bei der Vorhersage: {str(e)}")
    
    # Navigation Buttons (am Ende)
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("â¬…ï¸ ZurÃ¼ck zur Modellierung"):
            activate_component("modeling")
            st.rerun()
    
    with col2:
        if st.session_state.prediction_step == "results":
            if st.button("ðŸ”„ Neue Vorhersage"):
                st.session_state.prediction_step = "preparation"
                # Optional: Session state zurÃ¼cksetzen
                # st.session_state.loaded_models = {}
                # st.session_state.prediction_dataset = None  
                # st.session_state.prediction_columns = {}
                st.rerun()
    
    with col3:
        if st.button("ðŸ”„ Workflow neu starten"):
            activate_component("data_import")
            st.rerun()

else:
    # Startseite (unverÃ¤ndert)
    st.markdown("<h2 style='text-align: center;'>Willkommen bei der ML-Workflow-App</h2>", unsafe_allow_html=True)
    st.markdown("""
<div style='text-align: center; width: 100%;'>
    <p style='font-size: 1.2em;'>Diese App fÃ¼hrt Sie durch einen typischen maschinellen Lernablauf.</p>
    <div style='display: inline-block; text-align: left; max-width: 800px;'>
        <p style='font-size: 1em;'>1. <strong>Daten importieren</strong>: Laden Sie Ihre eigenen Daten hoch oder verwenden Sie Beispieldaten</p>
        <p style='font-size: 1em;'>2. <strong>Daten visualisieren</strong>: Untersuchen Sie Ihre Daten mit Scatter Plots und Feature-Statistiken</p>
        <p style='font-size: 1em;'>3. <strong>Datenbereinigung</strong>: WÃ¤hlen Sie Features und Zielvariablen aus</p>
        <p style='font-size: 1em;'>4. <strong>Daten-Sampling</strong>: Teilen Sie Ihre Daten in Trainings- und Testdaten auf</p>
        <p style='font-size: 1em;'>5. <strong>Modellierung</strong>: Trainieren Sie kNN- oder Entscheidungsbaum-Modelle</p>
        <p style='font-size: 1em;'>6. <strong>Evaluation</strong>: Bewerten Sie die Modellleistung mit Confusion Matrix und Metriken</p>
        <p style='font-size: 1em;'>7. <strong>Vorhersage</strong>: Unsere trainierten Modelle auf neuen DatensÃ¤tzen validieren</p>
    </div>        
    <p style="font-weight: bold; font-size: 1em; margin-top: 15px; color: #007E92;">Beginnen Sie in der Seitenleiste auf "<span style="text-decoration: underline;">1. Daten importieren</span>" klicken.</p>
</div>
""", unsafe_allow_html=True)

    # Beispiel-Workflow als Bild darstellen (optional)
    col1, col2, col3 = st.columns([1, 3, 1])
    with col2:
        image_path = os.path.join(os.path.dirname(__file__), "images", "logo.png")
        if os.path.exists(image_path):
            st.image(image_path)